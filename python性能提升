三、python性能提升
1. 使用内建函数:
你可以用Python写出高效的代码,但很难击败内建函数. 经查证. 他们非常快速.

2.使用join()连接字符串.
你可以使用 "+" 来连接字符串. 但由于string在Python中是不可变的,每一个"+"操作都会创建一个新的字符串并复制旧内容. 常见用法是使用Python的数组模块单个的修改字符;当完成的时候,使用 join() 函数创建最终字符串. 

3. 使用Python多重赋值，交换变量 
这在Python中即优雅又快速: 
      >>> x, y = y, x 
      这样很慢: 
      >>> temp = x 
      >>> x = y 
      >>> y = temp           

4. 尽量使用局部变量 
Python 检索局部变量比检索全局变量快. 这意味着,避免 "global" 关键字. 

5. 尽量使用 "in" 

6. 使用延迟加载加速 
將 "import" 声明移入函数中,仅在需要的时候导入. 换句话说,如果某些模块不需马上使用,稍后导入他们. 例如,你不必在一开使就导入大量模块而加速程序启动. 该技术不能提高整体性能. 但它可以帮助你更均衡的分配模块的加载时间. 

7. 为无限循环使用 "while 1" 
有时候在程序中你需一个无限循环.(例如一个监听套接字的实例) 尽管 "while true" 能完成同样的事, 但 "while 1" 是单步运算. 这招能提高你的Python性能.

8. 使用list comprehension 
list comprehension更具可读性（函数式编程），并在大多数情况下，它可以节省一个额外的计数变量。例如，让我们计算1到10之间的偶数个数： 
      >>> # the good way to iterate a range 
      >>> evens = [ i for i in range(10) if i%2 == 0] 
      >>> [0, 2, 4, 6, 8] 
      >>> # the following is not so Pythonic 
      >>> i = 0 
      >>> evens = [] 
      >>> while i < 10: 
      >>>    if i %2 == 0: evens.append(i) 
      >>>    i += 1 
      >>> [0, 2, 4, 6, 8] 

9. 使用xrange()处理长序列： 
这样可为你节省大量的系统内存，因为xrange()在序列中每次调用只产生一个整数元素。而相反 range()，它將直接给你一个完整的元素列表，用于循环时会有不必要的开销。

10. 使用 Python generator： 
这也可以节省内存和提高性能。例如一个视频流，你可以一个一个字节块的发送，而不是整个流。例如，      
      >>> chunk = ( 1000 * i for i in xrange(1000)) 
      >>> chunk 
      <generator object <genexpr> at 0x7f65d90dcaa0> 
      >>> chunk.next() 
      0 
      >>> chunk.next() 
      1000 
      >>> chunk.next() 
      2000 

11. 了解itertools模块： 
该模块对迭代和组合是非常有效的。让我们生成一个列表[1，2，3]的所有排列组合,仅需三行Python代码： 
      >>> import itertools 
      >>> iter = itertools.permutations([1,2,3]) 
      >>> list(iter) 
      [(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)] 

12. 学习bisect模块保持列表排序： 
这是一个免费的二分查找实现和快速插入有序序列的工具。也就是说，你可以使用： 
      >>> import bisect 
      >>> bisect.insort(list, element) 
      你已將一个元素插入列表中, 而你不需要再次调用 sort() 来保持容器的排序, 因为这在长序列中这会非常昂贵.

13. 理解Python列表，实际上是一个数组： 
Python中的列表实现并不是以人们通常谈论的计算机科学中的普通单链表实现的。Python中的列表是一个数组。也就是说，你可以以常量时间O(1) 检索列表的某个元素，而不需要从头开始搜索。这有什么意义呢？ Python开发人员使用列表对象insert（）时, 需三思. 例如：>>> list.insert（0，item） 
在列表的前面插入一个元素效率不高, 因为列表中的所有后续下标不得不改变. 然而，您可以使用list.append()在列表的尾端有效添加元素. 挑先deque，如果你想快速的在两插入或时。它是快速的，因为在Python中的deque用双链表实现。不再多说。 :) 

14. 使用dict 和 set 测试成员：
检查一个元素是在dicitonary或set是否存在 这在Python中非常快的。这是因为dict和set使用哈希表来实现。查找效率可以达到O(1)。因此，如果您需要经常检查成员，使用 set 或 dict做为你的容器. 
      >>> mylist = ['a', 'b', 'c'] #Slower, check membership with list: 
      >>> ‘c’ in mylist 
      >>> True 
      >>> myset = set(['a', 'b', 'c']) # Faster, check membership with set: 
      >>> ‘c’ in myset: 
      >>> True 

17. 理解Python的GIL（全局解释器锁）： 
GIL是必要的，因为CPython的内存管理是非线程安全的。你不能简单地创建多个线程，并希望Python能在多核心的机器上运行得更快。这是因为 GIL將会防止多个原生线程同时执行Python字节码。换句话说，GIL將序列化您的所有线程。然而，您可以使用线程管理多个派生进程加速程序，这些程 序独立的运行于你的Python代码外。 

因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。
GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。
所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。
不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。

